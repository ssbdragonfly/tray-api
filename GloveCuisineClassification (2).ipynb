{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EdEhqX_NHFdx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6Hj5WPQpHJPd"
      },
      "outputs": [],
      "source": [
        "train = pd.read_json('train.json')\n",
        "\n",
        "train['ingredients_str'] = train['ingredients'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "le = LabelEncoder()\n",
        "train['cuisine'] = le.fit_transform(train['cuisine'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aMUZGhQbHviu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train['ingredients_str'], train['cuisine'], test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_len = 100\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZw47guKIAzc",
        "outputId": "36147830-2e3c-4df3-91e6-cfbb0773eecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping line with formatting issue: standard -0.13416 0.47697 0.45242 0.2767 -0.25912 ...\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "        except ValueError:\n",
        "            print(f\"Skipping line with formatting issue: {line[:50]}...\")\n",
        "\n",
        "embedding_dim = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(20000, len(word_index) + 1)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= 20000:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "RyCiDMPrIB0D"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_test = le.transform(y_test)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_dim,\n",
        "                    input_length=max_len,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(le.classes_), activation='softmax'))\n",
        "\n",
        "optimizer = Adam(learning_rate=0.00001)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "h1rjZu1wISjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d928a6ea-0c98-4073-bcda-61a46af192e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "498/498 [==============================] - 13s 26ms/step - loss: 2.8054 - accuracy: 0.1838 - val_loss: 2.6554 - val_accuracy: 0.2106\n",
            "Epoch 2/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 2.6423 - accuracy: 0.1976 - val_loss: 2.5408 - val_accuracy: 0.2249\n",
            "Epoch 3/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.5460 - accuracy: 0.2220 - val_loss: 2.4701 - val_accuracy: 0.2415\n",
            "Epoch 4/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.4918 - accuracy: 0.2378 - val_loss: 2.4241 - val_accuracy: 0.2591\n",
            "Epoch 5/50\n",
            "498/498 [==============================] - 12s 25ms/step - loss: 2.4481 - accuracy: 0.2532 - val_loss: 2.3678 - val_accuracy: 0.2867\n",
            "Epoch 6/50\n",
            "498/498 [==============================] - 11s 22ms/step - loss: 2.3974 - accuracy: 0.2792 - val_loss: 2.3162 - val_accuracy: 0.3030\n",
            "Epoch 7/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.3557 - accuracy: 0.2946 - val_loss: 2.2785 - val_accuracy: 0.3189\n",
            "Epoch 8/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 2.3219 - accuracy: 0.3079 - val_loss: 2.2367 - val_accuracy: 0.3312\n",
            "Epoch 9/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 2.2900 - accuracy: 0.3181 - val_loss: 2.2034 - val_accuracy: 0.3449\n",
            "Epoch 10/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 2.2606 - accuracy: 0.3316 - val_loss: 2.1816 - val_accuracy: 0.3593\n",
            "Epoch 11/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 2.2322 - accuracy: 0.3411 - val_loss: 2.1454 - val_accuracy: 0.3710\n",
            "Epoch 12/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 2.2113 - accuracy: 0.3500 - val_loss: 2.1294 - val_accuracy: 0.3804\n",
            "Epoch 13/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 2.1905 - accuracy: 0.3574 - val_loss: 2.1031 - val_accuracy: 0.3868\n",
            "Epoch 14/50\n",
            "498/498 [==============================] - 10s 21ms/step - loss: 2.1710 - accuracy: 0.3646 - val_loss: 2.0857 - val_accuracy: 0.3927\n",
            "Epoch 15/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.1556 - accuracy: 0.3693 - val_loss: 2.0703 - val_accuracy: 0.3955\n",
            "Epoch 16/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.1407 - accuracy: 0.3755 - val_loss: 2.0618 - val_accuracy: 0.3991\n",
            "Epoch 17/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.1260 - accuracy: 0.3789 - val_loss: 2.0457 - val_accuracy: 0.4044\n",
            "Epoch 18/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 2.1115 - accuracy: 0.3846 - val_loss: 2.0295 - val_accuracy: 0.4063\n",
            "Epoch 19/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 2.1007 - accuracy: 0.3846 - val_loss: 2.0197 - val_accuracy: 0.4047\n",
            "Epoch 20/50\n",
            "498/498 [==============================] - 11s 22ms/step - loss: 2.0856 - accuracy: 0.3898 - val_loss: 2.0050 - val_accuracy: 0.4118\n",
            "Epoch 21/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.0761 - accuracy: 0.3901 - val_loss: 1.9957 - val_accuracy: 0.4128\n",
            "Epoch 22/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 2.0652 - accuracy: 0.3967 - val_loss: 1.9891 - val_accuracy: 0.4147\n",
            "Epoch 23/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 2.0531 - accuracy: 0.3976 - val_loss: 1.9763 - val_accuracy: 0.4197\n",
            "Epoch 24/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 2.0453 - accuracy: 0.4005 - val_loss: 1.9668 - val_accuracy: 0.4207\n",
            "Epoch 25/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.0373 - accuracy: 0.4029 - val_loss: 1.9571 - val_accuracy: 0.4253\n",
            "Epoch 26/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.0285 - accuracy: 0.4031 - val_loss: 1.9482 - val_accuracy: 0.4265\n",
            "Epoch 27/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 2.0175 - accuracy: 0.4072 - val_loss: 1.9419 - val_accuracy: 0.4269\n",
            "Epoch 28/50\n",
            "498/498 [==============================] - 11s 22ms/step - loss: 2.0126 - accuracy: 0.4072 - val_loss: 1.9336 - val_accuracy: 0.4287\n",
            "Epoch 29/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 2.0030 - accuracy: 0.4105 - val_loss: 1.9307 - val_accuracy: 0.4269\n",
            "Epoch 30/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9954 - accuracy: 0.4119 - val_loss: 1.9194 - val_accuracy: 0.4307\n",
            "Epoch 31/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 1.9880 - accuracy: 0.4126 - val_loss: 1.9115 - val_accuracy: 0.4309\n",
            "Epoch 32/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9787 - accuracy: 0.4187 - val_loss: 1.9082 - val_accuracy: 0.4342\n",
            "Epoch 33/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9719 - accuracy: 0.4196 - val_loss: 1.9006 - val_accuracy: 0.4354\n",
            "Epoch 34/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9688 - accuracy: 0.4209 - val_loss: 1.8921 - val_accuracy: 0.4378\n",
            "Epoch 35/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 1.9637 - accuracy: 0.4211 - val_loss: 1.8873 - val_accuracy: 0.4400\n",
            "Epoch 36/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9520 - accuracy: 0.4234 - val_loss: 1.8878 - val_accuracy: 0.4385\n",
            "Epoch 37/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 1.9459 - accuracy: 0.4260 - val_loss: 1.8800 - val_accuracy: 0.4400\n",
            "Epoch 38/50\n",
            "498/498 [==============================] - 12s 23ms/step - loss: 1.9426 - accuracy: 0.4277 - val_loss: 1.8699 - val_accuracy: 0.4420\n",
            "Epoch 39/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9375 - accuracy: 0.4269 - val_loss: 1.8669 - val_accuracy: 0.4434\n",
            "Epoch 40/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9322 - accuracy: 0.4284 - val_loss: 1.8682 - val_accuracy: 0.4454\n",
            "Epoch 41/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9259 - accuracy: 0.4299 - val_loss: 1.8574 - val_accuracy: 0.4479\n",
            "Epoch 42/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9180 - accuracy: 0.4346 - val_loss: 1.8550 - val_accuracy: 0.4476\n",
            "Epoch 43/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.9152 - accuracy: 0.4314 - val_loss: 1.8490 - val_accuracy: 0.4484\n",
            "Epoch 44/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 1.9100 - accuracy: 0.4353 - val_loss: 1.8481 - val_accuracy: 0.4494\n",
            "Epoch 45/50\n",
            "498/498 [==============================] - 11s 22ms/step - loss: 1.9089 - accuracy: 0.4348 - val_loss: 1.8420 - val_accuracy: 0.4497\n",
            "Epoch 46/50\n",
            "498/498 [==============================] - 11s 22ms/step - loss: 1.9055 - accuracy: 0.4363 - val_loss: 1.8434 - val_accuracy: 0.4509\n",
            "Epoch 47/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 1.9000 - accuracy: 0.4380 - val_loss: 1.8360 - val_accuracy: 0.4505\n",
            "Epoch 48/50\n",
            "498/498 [==============================] - 11s 23ms/step - loss: 1.8957 - accuracy: 0.4378 - val_loss: 1.8363 - val_accuracy: 0.4527\n",
            "Epoch 49/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.8896 - accuracy: 0.4421 - val_loss: 1.8343 - val_accuracy: 0.4523\n",
            "Epoch 50/50\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.8854 - accuracy: 0.4386 - val_loss: 1.8285 - val_accuracy: 0.4562\n",
            "  5/249 [..............................] - ETA: 3s - loss: 1.9062 - accuracy: 0.4250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "249/249 [==============================] - 3s 11ms/step - loss: 1.8285 - accuracy: 0.4562\n",
            "Model Accuracy: 45.62%\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(X_train_padded, y_train, epochs=50, validation_data=(X_test_padded, y_test), batch_size=64)\n",
        "\n",
        "model.save('improvedv2_cuisine_classification_model.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f\"Model Accuracy: {accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_KzgRy9Ig9X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}