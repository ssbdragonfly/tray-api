{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EdEhqX_NHFdx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence impofrt pad_sequences\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6Hj5WPQpHJPd"
      },
      "outputs": [],
      "source": [
        "train = pd.read_json('train.json')\n",
        "\n",
        "train['ingredients_str'] = train['ingredients'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "le = LabelEncoder()\n",
        "train['cuisine'] = le.fit_transform(train['cuisine'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aMUZGhQbHviu"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train['ingredients_str'], train['cuisine'], test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=20000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "max_len = 100\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZw47guKIAzc",
        "outputId": "7eccb792-a55f-4175-b1ee-1b539693cb96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping line with formatting issue: standard -0.13416 0.47697 0.45242 0.2767 -0.25912 ...\n"
          ]
        }
      ],
      "source": [
        "embeddings_index = {}\n",
        "with open('glove.6B.100d.txt', 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        try:\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "        except ValueError:\n",
        "            print(f\"Skipping line with formatting issue: {line[:50]}...\")\n",
        "\n",
        "embedding_dim = 100\n",
        "word_index = tokenizer.word_index\n",
        "num_words = min(20000, len(word_index) + 1)\n",
        "\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i >= 20000:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "RyCiDMPrIB0D"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words,\n",
        "                    output_dim=embedding_dim,\n",
        "                    input_length=max_len,\n",
        "                    weights=[embedding_matrix],\n",
        "                    trainable=False))\n",
        "model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Bidirectional(LSTM(64)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(len(le.classes_), activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1rjZu1wISjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1fd99b-2fac-4cd1-91b9-3218a592451e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "498/498 [==============================] - 19s 25ms/step - loss: 2.1990 - accuracy: 0.3552 - val_loss: 1.8896 - val_accuracy: 0.4430\n",
            "Epoch 2/20\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.8736 - accuracy: 0.4471 - val_loss: 1.7883 - val_accuracy: 0.4669\n",
            "Epoch 3/20\n",
            "498/498 [==============================] - 12s 24ms/step - loss: 1.7927 - accuracy: 0.4676 - val_loss: 1.7588 - val_accuracy: 0.4724\n",
            "Epoch 4/20\n",
            "433/498 [=========================>....] - ETA: 1s - loss: 1.7319 - accuracy: 0.4853"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_padded, y_train, epochs=20, validation_data=(X_test_padded, y_test), batch_size=64)\n",
        "\n",
        "model.save('improved_cuisine_classification_model.h5')\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "print(f'Model Accuracy: {accuracy * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_KzgRy9Ig9X"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}